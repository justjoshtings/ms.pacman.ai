{"cells":[{"cell_type":"markdown","metadata":{"id":"TEn5qZbFY_fe"},"source":["## **Table of Contents**\n","\n","\n","\n","1.   Setup\n","2.   OpenAI Gym Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSK_8bZLbLvS","executionInfo":{"status":"ok","timestamp":1646929208071,"user_tz":300,"elapsed":31328,"user":{"displayName":"Adam Kritz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lYIQwqHZkZ1IinfhS6pdbVs_lyzRIupbH5JO=s64","userId":"01718203511736331642"}},"outputId":"7978c648-9ff8-40f0-8fd0-1bc685a56fd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Collecting gym[accept-rom-license,atari]==0.22.0\n","  Downloading gym-0.22.0.tar.gz (631 kB)\n","\u001b[K     |████████████████████████████████| 631 kB 3.2 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]==0.22.0) (1.21.5)\n","Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]==0.22.0) (4.11.2)\n","Collecting gym-notices>=0.0.4\n","  Downloading gym_notices-0.0.5-py3-none-any.whl (2.7 kB)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]==0.22.0) (1.3.0)\n","Collecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Collecting ale-py~=0.7.4\n","  Downloading ale_py-0.7.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 48.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.4->gym[accept-rom-license,atari]==0.22.0) (5.4.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.22.0) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.22.0) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.22.0) (4.63.0)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->gym[accept-rom-license,atari]==0.22.0) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->gym[accept-rom-license,atari]==0.22.0) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.22.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.22.0) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.22.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.22.0) (2.10)\n","Building wheels for collected packages: gym, AutoROM.accept-rom-license\n","  Building wheel for gym (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.22.0-py3-none-any.whl size=708396 sha256=de4a6609417f12d941656249850d97a980b77f3e04bdc8c7ed38142af3f374e8\n","  Stored in directory: /root/.cache/pip/wheels/7d/5e/87/7d50e0179edda70feff5bba05c381041e1c1fd80c6b06a4cc3\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=d5f09dfee994c8858e7dbb258d13f7ec566f29507bbe40dd474008b560f5bbf4\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built gym AutoROM.accept-rom-license\n","Installing collected packages: gym-notices, AutoROM.accept-rom-license, autorom, gym, ale-py\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.17.3\n","    Uninstalling gym-0.17.3:\n","      Successfully uninstalled gym-0.17.3\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.4 autorom-0.4.2 gym-0.22.0 gym-notices-0.0.5\n"]}],"source":["# Installing OpenAI Gym and Arcade Learning Environment (ALE)\n","# https://github.com/openai/gym\n","# https://github.com/mgbellemare/Arcade-Learning-Environment\n","\n","!pip install gym gym[atari,accept-rom-license]==0.22.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QBnBFpInuYl","executionInfo":{"status":"ok","timestamp":1646929230932,"user_tz":300,"elapsed":22871,"user":{"displayName":"Adam Kritz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lYIQwqHZkZ1IinfhS6pdbVs_lyzRIupbH5JO=s64","userId":"01718203511736331642"}},"outputId":"0fbe6c13-78e2-4808-f39e-ef8041088638"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting colabgymrender\n","  Downloading colabgymrender-1.0.9-py3-none-any.whl (3.1 kB)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from colabgymrender) (0.2.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (1.21.5)\n","Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (2.4.1)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (4.63.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy->colabgymrender) (7.1.2)\n","Installing collected packages: colabgymrender\n","Successfully installed colabgymrender-1.0.9\n","Collecting pygame\n","  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n","\u001b[K     |████████████████████████████████| 21.8 MB 82.1 MB/s \n","\u001b[?25hInstalling collected packages: pygame\n","Successfully installed pygame-2.1.2\n"]}],"source":["# Colab render visualization setup\n","# source: https://yashk2000.github.io/blog/rendering-openai-gym-envs-in-colab/\n","\n","!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n","!pip install -U colabgymrender\n","!pip install pygame"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wm7PVvmbn5s8","executionInfo":{"status":"ok","timestamp":1646929239238,"user_tz":300,"elapsed":8324,"user":{"displayName":"Adam Kritz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lYIQwqHZkZ1IinfhS6pdbVs_lyzRIupbH5JO=s64","userId":"01718203511736331642"}},"outputId":"eb67f248-8eec-45ee-ec55-332d7bb3c97f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras-rl2\n","  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n","\u001b[?25l\r\u001b[K     |██████▎                         | 10 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 20 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 30 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 40 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 623 kB/s \n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.8.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.10.0.2)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.13.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (57.4.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.0.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.24.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (13.0.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.44.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.21.5)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-rl2) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.23.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.8.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.2.0)\n","Installing collected packages: tf-estimator-nightly, keras-rl2\n","Successfully installed keras-rl2-1.0.5 tf-estimator-nightly-2.8.0.dev2021122109\n"]}],"source":["# in order to complete the DQN import, need to pip install this\n","# for some reason the pip install is unique on colab, sourced from here: https://github.com/seungjaeryanlee/osim-rl-helper/issues/7\n","\n","!pip install keras-rl2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XBTSY2MPb3lF"},"outputs":[],"source":["# !pip freeze"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SvqOHMM6uef9"},"outputs":[],"source":["# You cant import these after the model creation for some reason, the sequentialmemory import messes up the model. Not sure why.\n","\n","from rl.agents import DQNAgent\n","from rl.memory import SequentialMemory, sample_batch_indexes, zeroed_observation, EpisodeParameterMemory\n","from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy, BoltzmannQPolicy, SoftmaxPolicy, GreedyQPolicy, MaxBoltzmannQPolicy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-dn4q930JpK","executionInfo":{"status":"ok","timestamp":1646929245857,"user_tz":300,"elapsed":1482,"user":{"displayName":"Adam Kritz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lYIQwqHZkZ1IinfhS6pdbVs_lyzRIupbH5JO=s64","userId":"01718203511736331642"}},"outputId":"ab22dbdf-50e1-4c4e-ec8c-e288ce8b69d6"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import gym\n","import ale_py\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","\n","import os\n","import shutil\n","\n","import numpy as np\n","\n","import warnings\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVIPk51OYDjC"},"outputs":[],"source":["# Ignore warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PyfooCJmZeY4"},"outputs":[],"source":["# Set matplotlib sizes\n","plt.rc('font', size=20)\n","plt.rc('axes', titlesize=20)\n","plt.rc('axes', labelsize=20)\n","plt.rc('xtick', labelsize=20)\n","plt.rc('ytick', labelsize=20)\n","plt.rc('legend', fontsize=20)\n","plt.rc('figure', titlesize=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zSHg1BRwZfO_"},"outputs":[],"source":["# Random Seed\n","\n","# The random seed\n","random_seed = 42\n","\n","# Set random seed in tensorflow\n","tf.random.set_seed(random_seed)\n","\n","# Set random seed in numpy\n","np.random.seed(random_seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5JF833dZjj3","executionInfo":{"status":"ok","timestamp":1646929246308,"user_tz":300,"elapsed":458,"user":{"displayName":"Adam Kritz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lYIQwqHZkZ1IinfhS6pdbVs_lyzRIupbH5JO=s64","userId":"01718203511736331642"}},"outputId":"db2ddd26-5713-4de2-e84a-d6035e19f3a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}],"source":["# Check what version of TF we are using\n","print(tf.version.VERSION)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtT-XoHVZlpL","executionInfo":{"status":"ok","timestamp":1646929246309,"user_tz":300,"elapsed":19,"user":{"displayName":"Adam Kritz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lYIQwqHZkZ1IinfhS6pdbVs_lyzRIupbH5JO=s64","userId":"01718203511736331642"}},"outputId":"837367ae-3fb0-4568-bfe7-30057465fedf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  0\n","GPU device not found\n"]}],"source":["# Print the number of GPUs available\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","\n","# Test to see if GPU is found and connected\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print('GPU device not found')\n","else:\n","  print('\\nFound GPU at: {}'.format(device_name))\n","  print('\\nCurrently using:')\n","  !nvidia-smi -L"]},{"cell_type":"markdown","metadata":{"id":"ryXgm4MxlISX"},"source":["Google Colab does not have a built in way to display, so we will have to create our own. There is a couple different methods to do this, but I was using method 3 found here: https://yashk2000.github.io/blog/rendering-openai-gym-envs-in-colab/ "]},{"cell_type":"markdown","metadata":{"id":"kYv69_4xA6V5"},"source":["# Visualization Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VHQR1y4yk82_","executionInfo":{"status":"ok","timestamp":1646929246310,"user_tz":300,"elapsed":12,"user":{"displayName":"Adam Kritz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lYIQwqHZkZ1IinfhS6pdbVs_lyzRIupbH5JO=s64","userId":"01718203511736331642"}},"outputId":"3f097ec8-b814-4ce4-a3e4-64aafa3ac4a8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Surface(1280x960x32 SW)>"]},"metadata":{},"execution_count":12}],"source":["# create a dummy environment to store the video of the game \n","# if we were to actually store the video we would have to remove the old video every time \n","# import os\n","os.environ['SDL_VIDEODRIVER']='dummy'\n","import pygame\n","pygame.display.set_mode((1280,960))\n","# we can make the display bigger here when we want to expand it"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9UR9t3uh3tY"},"outputs":[],"source":["# # A quick test using the example from the source\n","# from colabgymrender.recorder import Recorder\n","\n","# env = gym.make('CartPole-v0')\n","# directory = './video'\n","# env = Recorder(env, directory)\n","\n","# curr_state = env.reset()\n","# done = False\n","# while not done:\n","#   action = env.action_space.sample()\n","#   curr_state, _, done, info = env.step(action)\n","\n","# env.play()"]},{"cell_type":"markdown","metadata":{"id":"WA14oywGnUVn"},"source":["# Ms. Pacman Random Model\n","\n","Now let's try it with Ms. Pacman and the random model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCOvp534nFtN"},"outputs":[],"source":["# # Just messing around with gym - Josh\n","\n","env = gym.make('ALE/MsPacman-v5')\n","height, width, channels = env.observation_space.shape\n","actions = env.action_space.n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlGzAVB4uAwq"},"outputs":[],"source":["# print(height, width, channels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G4F-yak0nFtN"},"outputs":[],"source":["# # Our agent's possible actions\n","# env.unwrapped.get_action_meanings()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-yZV_xmhnFtO"},"outputs":[],"source":["# # testing the random model \n","# # code from here: https://www.youtube.com/watch?v=hCeJeq8U0lo\n","# # we remove env.render() and instead include env.play()\n","# # episodes is the number of games\n","# episodes = 1\n","# for episode in range(1, episodes+1):\n","#     state = env.reset()\n","#     done = False\n","#     score = 0 \n","    \n","#     while not done:\n","#         action = random.choice([0,1,2,3,4,5,6,7,8])\n","#         n_state, reward, done, info = env.step(action)\n","#         score+=reward\n","#     print('Episode:{} Score:{}'.format(episode, score))\n","#     env.play()\n","# env.close()\n","# # still probably better than I would do"]},{"cell_type":"markdown","metadata":{"id":"yd2oyml1dAzk"},"source":["# 2. Create a Deep Learning Model with Keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rm9zksPhdAzm"},"outputs":[],"source":["# Again taken from: https://www.youtube.com/watch?v=hCeJeq8U0lo\n","# Here we build the CNN. We can alter all of the model creation later in order to make the model as successful as possible\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Convolution2D\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VQIyEfFdAzn"},"outputs":[],"source":["def build_model(height, width, channels, actions):\n","    model = Sequential()\n","    model.add(Convolution2D(32, (8,8), strides=(4,4), activation='relu', input_shape=(3,height, width, channels)))\n","    model.add(Convolution2D(64, (4,4), strides=(2,2), activation='relu'))\n","    model.add(Convolution2D(64, (3,3), activation='relu'))\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(actions, activation='linear'))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZpccEb3w1cJC"},"outputs":[],"source":["# if you make a mistake, remember to delete the model\n","del model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_Nk2-ZTdAzr"},"outputs":[],"source":["model = build_model(height, width, channels, actions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MyGvhB0pdAzs","executionInfo":{"status":"ok","timestamp":1646929256203,"user_tz":300,"elapsed":21,"user":{"displayName":"Adam Kritz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lYIQwqHZkZ1IinfhS6pdbVs_lyzRIupbH5JO=s64","userId":"01718203511736331642"}},"outputId":"6067f956-b187-4145-bf07-613f0ba5c3be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 3, 51, 39, 32)     6176      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 3, 24, 18, 64)     32832     \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 22, 16, 64)     36928     \n","                                                                 \n"," flatten (Flatten)           (None, 67584)             0         \n","                                                                 \n"," dense (Dense)               (None, 512)               34603520  \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 9)                 2313      \n","                                                                 \n","=================================================================\n","Total params: 34,813,097\n","Trainable params: 34,813,097\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"_n_u96DPdAzs"},"source":["# 3. Build Agent with Keras-RL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eI3QXnJMdAzu"},"outputs":[],"source":["# here I needed to change enable_dueling_network to False, otherwise I was getting a recurssion error\n","def build_agent(model, actions):\n","    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.2, value_test=0.4, nb_steps=10000)\n","    memory = SequentialMemory(limit=100000, window_length=3)\n","    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n","                  enable_dueling_network=False, dueling_type='avg',\n","                   nb_actions=actions, nb_steps_warmup=100\n","                  )\n","    return dqn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tY4hjfA_dAzw"},"outputs":[],"source":["dqn = build_agent(model, actions)\n","dqn.compile(Adam(lr=1e-3))"]},{"cell_type":"code","source":["#, callbacks = callbacks"],"metadata":{"id":"17NIN9WiywUD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EcWCmyT2dAzw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4335c593-a4e4-42ab-d8f9-3239a5ba8596"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training for 3000 steps ...\n"]}],"source":["# this will take a very long time to run unless you lower the steps\n","# right now we are running at 2000 steps, with an 1000 step warmup in the agent, so it is barely fitting at all\n","# in the video he mentioned that the creators of the algorithm recommended to run this for 10 million steps, so that may be what we need the GPU EC2 instance for\n","# if you dont want to wait, just press the stop button on the cell and it will stop the model training where it is with no error\n","dqn.fit(env, nb_steps=3000, visualize=False, verbose=2)\n","#### I will see if I can figure out how to train the fitting process, as this is the funny part where our model looks stupid"]},{"cell_type":"code","source":["from colabgymrender.recorder import Recorder\n","directory = './video'\n","env = Recorder(env, directory)"],"metadata":{"id":"4sRskY0jKw8H"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hKOh3bCCdAzx"},"outputs":[],"source":["# this is not gonna be much better than the random model cause we are hardly training, just wanted to get it all working first\n","# I also created a loop so it will play the video of each test after each try, since we cannot use Visualize = True\n","# the model is already fit here, so each result does not build off the last one, these tests are their own independent trials (to my understanding)\n","i = 0\n","avg_calc = []\n","while i < 10:\n","  scores = dqn.test(env, nb_episodes=1, visualize=False)\n","  avg_calc.append(scores.history['episode_reward'][0])\n","  env.play()\n","  i += 1\n","print('Average Score:', sum(avg_calc)/len(avg_calc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75rT1EhD6ALz"},"outputs":[],"source":["# to save our model:\n","# dqn.save_weights('insertfilepathhere/dqn_weights.h5f')\n","# to load a model:\n","# del model, dqn\n","# dqn.load_weights('insertfilepathhere/dqn_weights.h5f')"]}],"metadata":{"colab":{"name":"Adam modeling stuff","provenance":[],"authorship_tag":"ABX9TyPxtq3wHLSwkF4d4wkdlYX3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}